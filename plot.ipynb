{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import math\n",
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brackets(text, brackets='[]'):\n",
    "    assert len(brackets) == 2\n",
    "    pattern = re.escape(brackets[0]) + r'(.*?)' + re.escape(brackets[1])\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "def extract_amout(\n",
    "    message, \n",
    "    prefix='',\n",
    "    print_except=True,\n",
    "    type=float,\n",
    "    brackets='[]'\n",
    "):\n",
    "    try:\n",
    "        matches = extract_brackets(message, brackets=brackets)\n",
    "        matches = [s[len(prefix):] \\\n",
    "            if s.startswith(prefix) \\\n",
    "            else s for s in matches]\n",
    "        invalid = False\n",
    "        if len(matches) == 0:\n",
    "            invalid = True\n",
    "        for i in range(len(matches)):\n",
    "            if matches[i] != matches[0]:\n",
    "                invalid = True\n",
    "        if invalid:\n",
    "            raise ValueError('Invalid answer: %s' % message)\n",
    "        return type(matches[0])\n",
    "    except Exception as e: \n",
    "        if print_except: print(e)\n",
    "        return None\n",
    "\n",
    "def extract_choices(recrods):\n",
    "    choices = [extract_amout(\n",
    "        messages[-1]['content'], \n",
    "        prefix='$', \n",
    "        print_except=True,\n",
    "        type=float) for messages in records['messages']\n",
    "    ]\n",
    "    choices = [x for x in choices if x is not None]\n",
    "    # print(choices)\n",
    "    return choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choices_to_df(choices, hue):\n",
    "    df = pd.DataFrame(choices, columns=['choices'])\n",
    "    df['hue'] = hue\n",
    "    df['hue'] = df['hue'].astype(str)\n",
    "    return df\n",
    "\n",
    "def plot(\n",
    "        df, \n",
    "        title='',\n",
    "        x='choices',\n",
    "        hue='hue',\n",
    "        binrange=None, \n",
    "        binwidth=None,\n",
    "        stat='count',\n",
    "        multiple='dodge'\n",
    "    ):\n",
    "    if binrange is None:\n",
    "        binrange = (df[x].min(), df[x].max())\n",
    "    df = df.dropna(axis=0, subset=[x]).reset_index()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.histplot(\n",
    "        data=df, \n",
    "        x=x,\n",
    "        hue=hue, \n",
    "        kde=True,\n",
    "        binrange=binrange, \n",
    "        binwidth=binwidth,\n",
    "        stat=stat,\n",
    "        multiple=multiple,\n",
    "        shrink=.8,\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_facet(\n",
    "    df_list,\n",
    "    x='choices',\n",
    "    hue='hue',\n",
    "    palette=None,\n",
    "    binrange=None,\n",
    "    bins=10,\n",
    "    # binwidth=10,\n",
    "    stat='count',\n",
    "    x_label='',\n",
    "    sharex=True,\n",
    "    sharey=False,\n",
    "    subplot=sns.histplot,\n",
    "    xticks_locs=None,\n",
    "    # kde=False,\n",
    "    **kwargs\n",
    "):\n",
    "    data = pd.concat(df_list)\n",
    "    if binrange is None:\n",
    "        binrange = (data[x].min(), data[x].max())\n",
    "    g = sns.FacetGrid(\n",
    "        data, row=hue, hue=hue, \n",
    "        palette=palette,\n",
    "        aspect=2, height=2, \n",
    "        sharex=sharex, sharey=sharey,\n",
    "        despine=True,\n",
    "    )\n",
    "    g.map_dataframe(\n",
    "        subplot, \n",
    "        x=x, \n",
    "        # kde=kde, \n",
    "        binrange=binrange, \n",
    "        bins=bins,\n",
    "        stat=stat,\n",
    "        **kwargs\n",
    "    )\n",
    "    # g.add_legend(title='hue')\n",
    "    g.set_axis_labels(x_label, stat.title())\n",
    "    g.set_titles(row_template=\"{row_name}\")\n",
    "    for ax in g.axes.flat:\n",
    "        ax.yaxis.set_major_formatter(\n",
    "            FuncFormatter(lambda y, pos: '{:.2f}'.format(y))\n",
    "        )\n",
    "    \n",
    "    binwidth = (binrange[1] - binrange[0]) / bins\n",
    "    if xticks_locs is None:\n",
    "        locs = np.linspace(binrange[0], binrange[1], bins//2+1)\n",
    "        locs = [loc + binwidth for loc in locs]\n",
    "    else: \n",
    "        locs = xticks_locs\n",
    "    labels = [str(int(loc)) for loc in locs]\n",
    "    locs = [loc + 0.5*binwidth for loc in locs]\n",
    "    plt.xticks(locs, labels)\n",
    "    \n",
    "    g.set(xlim=binrange)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "default_palette = sns.color_palette(None)\n",
    "blue = default_palette[0]\n",
    "orange = default_palette[1]\n",
    "green = default_palette[2]\n",
    "red = default_palette[3]\n",
    "purple = default_palette[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_occupations(\n",
    "    df_baseline,\n",
    "    choices_all,\n",
    "    binrange=(0,100),\n",
    "    binwidth=5,\n",
    "    x_label='$ to give',\n",
    "    stat='density',\n",
    "    model='ChatGPT-4',\n",
    "):\n",
    "    print('baseline: ', len(df_baseline))\n",
    "    df_list = []\n",
    "    for occupation in choices_all:\n",
    "        choices = choices_all[occupation]\n",
    "        print(occupation, ':', len(choices))\n",
    "        df = choices_to_df(choices, hue='{} ({})'.format(model, occupation))\n",
    "        df_list.append(df)\n",
    "    g = plot_facet(\n",
    "        df_list=[df_baseline]+df_list,\n",
    "        binrange=binrange,\n",
    "        binwidth=binwidth,\n",
    "        x_label=x_label,\n",
    "        stat=stat,\n",
    "    )\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 2: Turing Test\n",
    "\n",
    "Results may vary due to randomness in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def simulate_Turing(samples_0, samples_1, n_bin=10, lim_a=0, lim_b=100, n_draw=100000):\n",
    "#     hist_0 = np.histogram(samples_0, bins=n_bin, range=(lim_a, lim_b))[0] / len(samples_0)\n",
    "#     n_wins = 0\n",
    "#     n_ties = 0\n",
    "#     for _ in tqdm(range(n_draw)):\n",
    "#         try:\n",
    "#             sample_0 = np.random.choice(samples_0)\n",
    "#             sample_1 = np.random.choice(samples_1)\n",
    "#             idx_0 = min(math.floor((sample_0 - lim_a) / (lim_b - lim_a) * n_bin), n_bin-1)\n",
    "#             idx_1 = min(math.floor((sample_1 - lim_a) / (lim_b - lim_a) * n_bin), n_bin-1)\n",
    "#             if hist_0[idx_1] > hist_0[idx_0]:\n",
    "#                 n_wins += 1\n",
    "#             elif hist_0[idx_1] == hist_0[idx_0]:\n",
    "#                 n_ties += 1\n",
    "#         except:\n",
    "#             continue\n",
    "#     return n_wins / n_draw, n_ties / n_draw, (n_draw - n_wins - n_ties) / n_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', simulate_Turing(df_dictator_human['choices'], df_dictator_human['choices']))\n",
    "# print('gpt4', simulate_Turing(df_dictator_human['choices'], df_dictator_gpt4['choices']))\n",
    "# print('turbo', simulate_Turing(df_dictator_human['choices'], df_dictator_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_human['choices']))\n",
    "# print('gpt4', simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_gpt4['choices']))\n",
    "# print('turbo', simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_human['choices']))\n",
    "# print('gpt4', simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_gpt4['choices']))\n",
    "# print('turbo', simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', simulate_Turing(df_trust_1_human['choices'], df_trust_1_human['choices']))\n",
    "# print('gpt4', simulate_Turing(df_trust_1_human['choices'], df_trust_1_gpt4['choices']))\n",
    "# print('turbo', simulate_Turing(df_trust_1_human['choices'], df_trust_1_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', simulate_Turing(df_trust_3_human['choices'], df_trust_3_human['choices'], lim_b=150))\n",
    "# print('gpt4', simulate_Turing(df_trust_3_human['choices'], df_trust_3_gpt4['choices'], lim_b=150))\n",
    "# print('turbo', simulate_Turing(df_trust_3_human['choices'], df_trust_3_turbo['choices'], lim_b=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to numeric, coercing errors (invalid parsing will be set as NaN)\n",
    "# samples_0 = pd.to_numeric(df_PG_human['choices'], errors='coerce')\n",
    "# samples_1 = pd.to_numeric(df_PG_gpt4['choices'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_PG_turbo['choices'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_PG_turbo['choices'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# nan_count = df_PG_turbo['choices'].isna().sum()\n",
    "# print(f\"Number of NaN values: {nan_count}\")\n",
    "\n",
    "df_PG_turbo['choices'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_PG_turbo['choices'] = df_PG_turbo['choices'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', simulate_Turing(df_PG_human['choices'], df_PG_human['choices'], lim_b=20))\n",
    "# print('gpt4', simulate_Turing(df_PG_human['choices'], df_PG_gpt4['choices'], lim_b=20))\n",
    "# print('gpt4', simulate_Turing(df_PG_turbo['choices'], df_PG_turbo['choices'], lim_b=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_human['']))\n",
    "# print('gpt4', simulate_Turing(prefix_to_choices_human[''],prefix_to_choices_model['ChatGPT-4']['']))\n",
    "# print('turbo', simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_model['ChatGPT-3']['']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('human', r_coo_human * r_def_human, r_coo_human * r_coo_human + r_def_human * r_def_human, r_def_human * r_coo_human)\n",
    "# print('gpt4', r_coo_human * r_def_gpt4, r_coo_human * r_coo_gpt4 + r_def_human * r_def_gpt4, r_def_human * r_coo_gpt4)\n",
    "# print('turbo', r_coo_human * r_def_turbo, r_coo_human * r_coo_turbo + r_def_human * r_def_turbo, r_def_human * r_coo_turbo)\n",
    "\n",
    "# n_coo_human = 36269\n",
    "# n_def_human = 44114\n",
    "# r_coo_human = n_coo_human / (n_coo_human + n_def_human)\n",
    "# r_def_human = n_def_human / (n_coo_human + n_def_human)\n",
    "# print(r_coo_human, r_def_human)\n",
    "\n",
    "# n_coo_gpt4 = 29 + 0 + 0 + 26\n",
    "# n_def_gpt4 = 0 + 1 + 1 + 3\n",
    "# n_coo_turbo = 21 + 3 + 7 + 15\n",
    "# n_def_turbo = 3 + 3 + 4 + 4\n",
    "# r_coo_gpt4 = n_coo_gpt4 / (n_coo_gpt4 + n_def_gpt4)\n",
    "# r_def_gpt4 = n_def_gpt4 / (n_coo_gpt4 + n_def_gpt4)\n",
    "# r_coo_turbo = n_coo_turbo / (n_coo_turbo + n_def_turbo)\n",
    "# r_def_turbo = n_def_turbo / (n_coo_turbo + n_def_turbo)\n",
    "# print(r_coo_gpt4, r_def_gpt4)\n",
    "# print(r_coo_turbo, r_def_turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# player_average('human', df_dictator_human['choices'])\n",
    "# player_average('gpt4', df_dictator_gpt4['choices'])\n",
    "# player_average('turbo', df_dictator_turbo['choices'])\n",
    "\n",
    "# player_average('human', [1]*n_coo_human + [0]*n_def_human)\n",
    "# player_average('gpt4', [1]*n_coo_gpt4 + [0]*n_def_gpt4)\n",
    "# player_average('turbo', [1]*n_coo_turbo + [0]*n_def_turbo)\n",
    "\n",
    "\n",
    "# Average_human_result = simulate_Turing(df_average_human['choices'], df_average_human['choices'])\n",
    "# Average_gpt4_result = simulate_Turing(df_average_human['choices'], df_average_gpt4['choices'])\n",
    "# Average_turbo_result = simulate_Turing(df_average_human['choices'], df_average_turbo['choices'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Dictator_human_result = simulate_Turing(df_dictator_human['choices'], df_dictator_human['choices'])\n",
    "# Dictator_gpt4_result = simulate_Turing(df_dictator_human['choices'], df_dictator_gpt4['choices'])\n",
    "# Dictator_turbo_result = simulate_Turing(df_dictator_human['choices'], df_dictator_turbo['choices'])\n",
    "\n",
    "# Ultimatum_1_human_result = simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_human['choices'])\n",
    "# Ultimatum_1_gpt4_result = simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_gpt4['choices'])\n",
    "# Ultimatum_1_turbo_result = simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_turbo['choices'])\n",
    "\n",
    "# Ultimatum_2_human_result = simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_human['choices'])\n",
    "# Ultimatum_2_gpt4_result = simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_gpt4['choices'])\n",
    "# Ultimatum_2_turbo_result = simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_turbo['choices'])\n",
    "\n",
    "# Trust_1_human_result = simulate_Turing(df_trust_1_human['choices'], df_trust_1_human['choices'])\n",
    "# Trust_1_gpt4_result = simulate_Turing(df_trust_1_human['choices'], df_trust_1_gpt4['choices'])\n",
    "# Trust_1_turbo_result = simulate_Turing(df_trust_1_human['choices'], df_trust_1_turbo['choices'])\n",
    "\n",
    "# Trust_3_human_result = simulate_Turing(df_trust_3_human['choices'], df_trust_3_human['choices'], lim_b=150)\n",
    "# Trust_3_gpt4_result = simulate_Turing(df_trust_3_human['choices'], df_trust_3_gpt4['choices'], lim_b=150)\n",
    "# Trust_3_turbo_result = simulate_Turing(df_trust_3_human['choices'], df_trust_3_turbo['choices'], lim_b=150)\n",
    "\n",
    "# Public_Goods_human_result = simulate_Turing(df_PG_human['choices'], df_PG_human['choices'], lim_b=20)\n",
    "# Public_Goods_gpt4_result = simulate_Turing(df_PG_human['choices'], df_PG_gpt4['choices'], lim_b=20)\n",
    "# Public_Goods_turbo_result = simulate_Turing(df_PG_turbo['choices'], df_PG_turbo['choices'], lim_b=20)\n",
    "\n",
    "# Bomb_Risk_human_result = simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_human[''])\n",
    "# Bomb_Risk_gpt4_result = simulate_Turing(prefix_to_choices_human[''],prefix_to_choices_model['ChatGPT-4'][''])\n",
    "# Bomb_Risk_turbo_result = simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_model['ChatGPT-3'][''])\n",
    "\n",
    "# Prisoner_Dilemma_human_result = r_coo_human * r_def_human, r_coo_human * r_coo_human + r_def_human * r_def_human, r_def_human * r_coo_human\n",
    "# Prisoner_Dilemma_gpt4_result = r_coo_human * r_def_gpt4, r_coo_human * r_coo_gpt4 + r_def_human * r_def_gpt4, r_def_human * r_coo_gpt4\n",
    "# Prisoner_Dilemma_turbo_result = r_coo_human * r_def_turbo, r_coo_human * r_coo_turbo + r_def_human * r_def_turbo, r_def_human * r_coo_turbo\n",
    "\n",
    "\n",
    "# data = {\n",
    "#     # 'Average': {\n",
    "#     #     'Human': Average_human_result,\n",
    "#     #     'GPT-4': Average_gpt4_result,\n",
    "#     #     'Turbo': Average_turbo_result,\n",
    "#     # },\n",
    "#     'Dictator': {\n",
    "#         'Human': Dictator_human_result,\n",
    "#         'GPT-4': Dictator_gpt4_result,\n",
    "#         'Turbo': Dictator_turbo_result,\n",
    "#     },\n",
    "#     'Ultimatum 1': {\n",
    "#         'Human': Ultimatum_1_human_result,\n",
    "#         'GPT-4': Ultimatum_1_gpt4_result,\n",
    "#         'Turbo': Ultimatum_1_turbo_result,\n",
    "#     },\n",
    "#     'Ultimatum 2': {\n",
    "#         'Human': Ultimatum_2_human_result,\n",
    "#         'GPT-4': Ultimatum_2_gpt4_result,\n",
    "#         'Turbo': Ultimatum_2_turbo_result,\n",
    "#     },\n",
    "#     'Trust 1': {\n",
    "#         'Human': Trust_1_human_result,\n",
    "#         'GPT-4': Trust_1_gpt4_result,\n",
    "#         'Turbo': Trust_1_turbo_result,\n",
    "#     },\n",
    "#     'Trust 3': {\n",
    "#         'Human': Trust_3_human_result,\n",
    "#         'GPT-4': Trust_3_gpt4_result,\n",
    "#         'Turbo': Trust_3_turbo_result,\n",
    "#     },\n",
    "#     'Public Goods': {\n",
    "#         'Human': Public_Goods_human_result,\n",
    "#         'GPT-4': Public_Goods_gpt4_result,\n",
    "#         'Turbo': Public_Goods_turbo_result,\n",
    "#     },\n",
    "#     'Bomb Risk': {\n",
    "#         'Human': Bomb_Risk_human_result,\n",
    "#         'GPT-4': Bomb_Risk_gpt4_result,\n",
    "#         'Turbo': Bomb_Risk_turbo_result,\n",
    "#     },\n",
    "#     'Prisoner‘s Dilemma': {\n",
    "#         'Human': Prisoner_Dilemma_human_result,\n",
    "#         'GPT-4': Prisoner_Dilemma_gpt4_result,\n",
    "#         'Turbo': Prisoner_Dilemma_turbo_result,\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# data = {\n",
    "    \n",
    "#     'Average': {\n",
    "#         'Human': (0.39472, 0.20789, 0.39539),\n",
    "#         'GPT-4': (0.45068, 0.20923, 0.34009),\n",
    "#         'Turbo': (0.14191, 0.10243, 0.75566),\n",
    "#     },\n",
    "#     'Dictator': {\n",
    "#         'Human': (0.39672, 0.20789, 0.39539),\n",
    "#         'GPT-4': (0.45068, 0.20923, 0.34009),\n",
    "#         'Turbo': (0.14191, 0.10243, 0.75566),\n",
    "#     },\n",
    "#     'Ultimatum 1': {\n",
    "#         'Human': (0.39641, 0.20612, 0.39747),\n",
    "#         'GPT-4': (0.65658, 0.34342, 0.0),\n",
    "#         'Turbo': (0.35094, 0.19359, 0.45547),\n",
    "#     },\n",
    "#     'Ultimatum 2': {\n",
    "#         'Human': (0.4103, 0.17962, 0.41008),\n",
    "#         'GPT-4': (0.38777, 0.18544, 0.42679),\n",
    "#         'Turbo': (0.23764, 0.12665, 0.63571),\n",
    "#     },\n",
    "#     'Trust 1': {\n",
    "#         'Human': (0.42553, 0.1499, 0.42457),\n",
    "#         'GPT-4': (0.24883, 0.0994, 0.65177),\n",
    "#         'Turbo': (0.22511, 0.09314, 0.68175),\n",
    "#     },\n",
    "#     'Trust 3': {\n",
    "#         'Human': (0.41412, 0.17279, 0.41309),\n",
    "#         'GPT-4': (0.52801, 0.18393, 0.28806),\n",
    "#         'Turbo': (0.52552, 0.17863, 0.29585),\n",
    "#     },\n",
    "#     'Public Goods': {\n",
    "#         'Human': (0.42576, 0.14121, 0.43303),\n",
    "#         'GPT-4': (0.63608, 0.20542, 0.1585),\n",
    "#         'Turbo': (0.0, 1.0, 0.0),\n",
    "#     },\n",
    "#     'Bomb Risk': {\n",
    "#         'Human': (0.43803, 0.12385, 0.43812),\n",
    "#         'GPT-4': (0.66265, 0.18317, 0.15418),\n",
    "#         'Turbo': (0.61836, 0.18062, 0.20102),\n",
    "#     },\n",
    "#     'Prisoner‘s Dilemma': {\n",
    "#         'Human': (0.24761879117560937, 0.5047624176487813, 0.24761879117560937),\n",
    "#         'GPT-4': (0.03760019738833667, 0.4593353072167, 0.5030644953949632),\n",
    "#         'Turbo': (0.10528055268734268, 0.473974596618688, 0.42074485069396933),\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Transform the data into a format suitable for Altair\n",
    "# records = []\n",
    "# for scenario, scenario_data in data.items():\n",
    "#     for entity, values in scenario_data.items():\n",
    "#         records.append({\n",
    "#             \"scenario\": scenario,\n",
    "#             \"entity\": entity,\n",
    "#             \"Estimated More likely Human\": values[0],\n",
    "#             \"Estimated Equally likely Human/AI\": values[1],\n",
    "#             \"Estimated More Likely AI\": values[2]\n",
    "#         })\n",
    "\n",
    "# # Create a DataFrame\n",
    "# df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# # Melt the DataFrame to have category names and percentages in separate columns\n",
    "# df_melted = df.melt(id_vars=['scenario', 'entity'], \n",
    "#                     value_vars=['Estimated More likely Human', 'Estimated Equally likely Human/AI', 'Estimated More Likely AI'],\n",
    "#                     var_name='category', value_name='percentage')\n",
    "\n",
    "# # Define the color scale\n",
    "# color_scale = alt.Scale(domain=['Estimated More likely Human', 'Estimated Equally likely Human/AI', 'Estimated More Likely AI'],\n",
    "#                         range=['#2ca02c', '#ff7f0e', '#d62728'])\n",
    "\n",
    "# # Create the selection for the interactive highlight\n",
    "# highlight = alt.selection_multi(on='mouseover',fields=['entity'], empty='none')\n",
    "# # alt.selection_single(on='mouseover', fields=['category'], empty='none')\n",
    "\n",
    "# # Define the base chart with a bar mark and the selection highlight\n",
    "# base_chart = alt.Chart(df_melted).mark_bar().encode(\n",
    "#     x=alt.X('sum(percentage)', stack=\"normalize\", title='', axis=alt.Axis(format='.0%')),\n",
    "#     y=alt.Y('entity:N', title='', sort=alt.EncodingSortField('entity', op='min', order='descending')),\n",
    "#     color=alt.Color('category', scale=color_scale),\n",
    "#     opacity=alt.condition(highlight, alt.value(1), alt.value(0.2)),\n",
    "#     tooltip=[alt.Tooltip('scenario'), alt.Tooltip('entity'), alt.Tooltip('category'), alt.Tooltip('sum(percentage):Q', format='.2%')]\n",
    "# ).properties(\n",
    "#     width=450,  # Width of the individual charts\n",
    "#     height=200\n",
    "# ).add_selection(\n",
    "#     highlight\n",
    "# )\n",
    "\n",
    "# # Facet the base chart into two rows\n",
    "# faceted_chart = base_chart.facet(\n",
    "#     facet=alt.Facet('scenario', title='', header=alt.Header(labelOrient='top', titleOrient='top')),\n",
    "#     columns=3  # Display four graphs in each column\n",
    "# )\n",
    "\n",
    "# # Adjust spacing between the rows for better readability\n",
    "# faceted_chart = faceted_chart.configure_facet(spacing=10)\n",
    "\n",
    "# # Show the chart\n",
    "# faceted_chart\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 3: Distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictator Game\n",
    "\n",
    "#### Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "binrange = (0, 100)\n",
    "moves = []\n",
    "with open('data/dictator.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    col2idx = {col: idx for idx, col in enumerate(header)}\n",
    "    for row in reader:\n",
    "        record = {col: row[idx] for col, idx in col2idx.items()}\n",
    "\n",
    "        if record['Role'] != 'first': continue\n",
    "        if int(record['Round']) > 1: continue\n",
    "        if int(record['Total']) != 100: continue\n",
    "        if record['move'] == 'None': continue\n",
    "        if record['gameType'] != 'dictator': continue\n",
    "\n",
    "        move = float(record['move'])\n",
    "        if move < binrange[0] or \\\n",
    "            move > binrange[1]: continue\n",
    "        \n",
    "        moves.append(move)\n",
    "\n",
    "df_dictator_human = choices_to_df(moves, 'Human')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0]\n",
    "df_dictator_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "\n",
    "choices = [25, 35, 70, 30, 20, 25, 40, 80, 30, 30, 40, 30, 30, 30, 30, 30, 40, 40, 30, 30, 40, 30, 60, 20, 40, 25, 30, 30, 30]\n",
    "df_dictator_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(df_dictator_gpt4.dropna()))\n",
    "print(len(df_dictator_turbo.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid answer: Sure, here's my choice: \n",
      "\n",
      "I would divide the money as follows: \n",
      "- I would give [$35] to the other player.\n",
      "- I would keep [$65] for myself. \n",
      "\n",
      "This way, the other player still gets a significant amount of money, but I also keep a majority of it.\n",
      "Invalid answer: Sure, here's how I would divide the $100: \n",
      "\n",
      "I would keep [$30] for myself and give the other player [$70].\n",
      "Invalid answer: Here's one way to divide the $100: \n",
      "\n",
      "I will give [$30] to the other player and keep the remaining [$70].\n",
      "Invalid answer: Sure, here's one way to divide the money:\n",
      "\n",
      "I would give the other player [$25] and keep [$75] for myself.\n",
      "Invalid answer: Sure! Here's my choice: \n",
      "\n",
      "I would divide the money with $80 for the other player [$80] and $20 for myself [$20]. I believe this is a fair division as the other player will receive a significant amount of money, while I will still receive a portion for my participation.\n",
      "Invalid answer: Sure! Here's one possible way to divide the money: \n",
      "\n",
      "You can keep [$70], and give the other player [$30].\n",
      "Invalid answer: Sure, here's my choice: I would give [$30] to the other player and keep the remaining [$70].\n",
      "Invalid answer: Alright, here is one possible way to divide the $100:\n",
      "\n",
      "I would give [$40] to the other player and keep the remaining [$60] for myself.\n",
      "Invalid answer: Sure, here's my suggestion:\n",
      "\n",
      "I would divide the money as follows: \n",
      "\n",
      "- I would keep [$70].\n",
      "- The other player would receive [$30].\n",
      "Invalid answer: Great, here's my choice: I would divide the money as follows: I keep [$70] and give the other player [$30].\n",
      "Invalid answer: Sure, here's my choice: \n",
      "I would divide the money in the following way: \n",
      "\n",
      "I would give [$30] to the other player and keep the remaining [$70] for myself.\n",
      "Invalid answer: Here's my choice: I would give [$30] to the other player and keep [$70] for myself.\n",
      "Invalid answer: Sure, if I were paired with another player and had to divide $100 between us, I would choose to give them [$40] and keep [$60] for myself.\n",
      "Invalid answer: Sure, here's the breakdown:\n",
      "\n",
      "I would give [$30] to the other player and keep the remaining [$70] for myself.\n",
      "Invalid answer: Sure, here's my choice: I would give [$30] to the other player and keep [$70] for myself.\n",
      "Invalid answer: Sure, here's one possible way to divide the $100: \n",
      "\n",
      "I would keep [$60] and give the other player [$40].\n",
      "Invalid answer: Sure, I'm happy to play this game with you! \n",
      "\n",
      "Here's how I would divide the $100: \n",
      "\n",
      "I would give [$30] to the other player and keep [$70] for myself.\n",
      "Invalid answer: I would divide the money in the following way: [$60] for the other player and [$40] for myself.\n",
      "Invalid answer: Sure, here's my choice: \n",
      "\n",
      "I would give [$20] to the other player, keeping the remaining [$80] for myself.\n",
      "Invalid answer: Sure! Here's one possible way to divide the money: \n",
      "\n",
      "I would give the other player [$40] and keep [$60] for myself.\n",
      "Invalid answer: Sure, here's my proposal: \n",
      "\n",
      "I would divide the money as follows: \n",
      "\n",
      "- Give [$25] to the other player. \n",
      "- Keep [$75] for myself. \n",
      "\n",
      "That way, the other player gets a decent amount while I also get a significant share of the money.\n",
      "Invalid answer: Sure! Here's one possible way to divide the money: \n",
      "\n",
      "You receive: [$70], the other player receives: [$30]. \n",
      "\n",
      "Is this the choice you were looking for?\n",
      "Invalid answer: Sure, here's my proposal: I would divide the money as follows: I'll give [$30] to the other player and keep the remaining [$70] for myself.\n",
      "Invalid answer: Sure, I will provide you with one possible option for dividing the $100. \n",
      "\n",
      "I choose to keep [$70] for myself and give the other player [$30].\n",
      "25.0, 20.0, 40.0, 30.0, 40.0\n"
     ]
    }
   ],
   "source": [
    "records = json.load(open('records/dictator_wo_ex_2023_03_13-11_24_07_PM.json', 'r'))\n",
    "choices = extract_choices(records)\n",
    "print(', '.join([str(x) for x in choices]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ultimatum Game\n",
    "\n",
    "#### Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ultimatum_strategy.csv')\n",
    "df = df[df['gameType'] == 'ultimatum_strategy']\n",
    "df = df[df['Role'] == 'player']\n",
    "df = df[df['Round'] == 1]\n",
    "df = df[df['Total'] == 100]\n",
    "df = df[df['move'] != 'None']\n",
    "df['propose'] = df['move'].apply(lambda x: eval(x)[0])\n",
    "df['accept'] = df['move'].apply(lambda x: eval(x)[1])\n",
    "df = df[(df['propose'] >= 0) & (df['propose'] <= 100)]\n",
    "df = df[(df['accept'] >= 0) & (df['accept'] <= 100)]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ultimatum_1_human = choices_to_df(list(df['propose']), 'Human')\n",
    "df_ultimatum_2_human = choices_to_df(list(df['accept']), 'Human')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0]\n",
    "df_ultimatum_1_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "\n",
    "choices = [40, 40, 40, 30, 70, 70, 50, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 30, 30, 35, 50, 40, 70, 40, 60, 60, 70, 40, 50]\n",
    "df_ultimatum_1_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))\n",
    "\n",
    "choices = [50.0, 50.0, 50.0, 1.0, 1.0, 1.0, 50.0, 25.0, 50.0, 1.0, 1.0, 20.0, 50.0, 50.0, 50.0, 20.0, 50.0, 1.0, 1.0, 1.0, 50.0, 50.0, 50.0, 1.0, 1.0, 1.0, 20.0, 1.0] + [0, 1]\n",
    "df_ultimatum_2_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "\n",
    "choices = [None, 50, 50, 50, 50, 30, None, None, 30, 33.33, 40, None, 50, 40, None, 1, 30, None, 10, 50, 30, 10, 30, None, 30, None, 10, 30, 30, 30]\n",
    "df_ultimatum_2_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n",
      "30\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(df_ultimatum_1_gpt4.dropna()))\n",
    "print(len(df_ultimatum_1_turbo.dropna()))\n",
    "\n",
    "print(len(df_ultimatum_2_gpt4.dropna()))\n",
    "print(len(df_ultimatum_2_turbo.dropna()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [50.0, 50.0, 50.0, 1.0, 1.0, 1.0, 50.0, 25.0, 50.0, 1.0, 1.0, 20.0, 50.0, 50.0, 50.0, 20.0, 50.0, 1.0, 1.0, 1.0, 50.0, 50.0, 50.0, 1.0, 1.0, 1.0, 20.0, 1.0] + [0, 1]\n",
    "df_ultimatum_2_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4 (0314, 04.05)'))\n",
    "\n",
    "# records = json.load(open('records/ultimatum_2_gpt4_2023_12_29-10_42_42_PM.json', 'r'))\n",
    "# choices = extract_choices(records)\n",
    "# df_ultimatum_2_gpt4_1229 = choices_to_df(choices, hue=str('ChatGPT-4 (0314, 12.29)'))\n",
    "\n",
    "# records = json.load(open('records/ultimatum_2_gpt4_1106_2023_12_29-11_15_35_PM.json', 'r'))\n",
    "# choices = extract_choices(records)\n",
    "# df_ultimatum_2_gpt4_1106_1229 = choices_to_df(choices, hue=str('ChatGPT-4 (1106, 12.29)'))\n",
    "\n",
    "# plot_facet(\n",
    "#     df_list=[\n",
    "#         df_ultimatum_2_gpt4,\n",
    "#         df_ultimatum_2_gpt4_1229,\n",
    "#         df_ultimatum_2_gpt4_1106_1229,\n",
    "#     ],\n",
    "#     binrange=(0, 100),\n",
    "#     # binwidth=10,\n",
    "#     stat='density',\n",
    "#     x_label='Minimum proposal to accept ($)',\n",
    "# )\n",
    "# plt.savefig('figures/repro-ultimatum-respond.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [None, 50, 50, 50, 50, 30, None, None, 30, 33.33, 40, None, 50, 40, None, 1, 30, None, 10, 50, 30, 10, 30, None, 30, None, 10, 30, 30, 30]\n",
    "df_ultimatum_2_turbo = choices_to_df(choices, hue=str('ChatGPT-3 (0301, 03.13)'))\n",
    "\n",
    "# records = json.load(open('records/ultimatum_2_turbo_2023_12_29-10_43_41_PM.json', 'r'))\n",
    "# choices = extract_choices(records)\n",
    "# df_ultimatum_2_turbo_1229 = choices_to_df(choices, hue=str('ChatGPT-3 (0301, 12.29)'))\n",
    "\n",
    "# records = json.load(open('records/ultimatum_2_turbo_1106_2023_12_29-11_57_30_PM.json', 'r'))\n",
    "# choices = extract_choices(records)\n",
    "# df_ultimatum_2_turbo_1106_1229 = choices_to_df(choices, hue=str('ChatGPT-3 (1106, 12.29)'))\n",
    "\n",
    "# plot_facet(\n",
    "#     df_list=[\n",
    "#         df_ultimatum_2_turbo,\n",
    "#         df_ultimatum_2_turbo_1229,\n",
    "#         df_ultimatum_2_turbo_1106_1229,\n",
    "#     ],\n",
    "#     binrange=(0, 100),\n",
    "#     # binwidth=10,\n",
    "#     stat='density',\n",
    "#     x_label='Minimum proposal to accept ($)',\n",
    "# )\n",
    "# # plt.savefig('figures/cmp-ultimatum-respond.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust Game\n",
    "\n",
    "#### Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "binrange = (0, 100)\n",
    "moves_1 = []\n",
    "moves_2 = defaultdict(list)\n",
    "with open('data/trust_investment.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    col2idx = {col: idx for idx, col in enumerate(header)}\n",
    "    for row in reader:\n",
    "        record = {col: row[idx] for col, idx in col2idx.items()}\n",
    "\n",
    "        # if record['Role'] != 'first': continue\n",
    "        if int(record['Round']) > 1: continue\n",
    "        # if int(record['Total']) != 100: continue\n",
    "        if record['move'] == 'None': continue\n",
    "        if record['gameType'] != 'trust_investment': continue\n",
    "\n",
    "        if record['Role'] == 'first':\n",
    "            move = float(record['move'])\n",
    "            if move < binrange[0] or \\\n",
    "                move > binrange[1]: continue\n",
    "            moves_1.append(move)\n",
    "        elif record['Role'] == 'second':\n",
    "            inv, ret = eval(record['roundResult'])\n",
    "            if ret < 0 or \\\n",
    "                ret > inv * 3: continue\n",
    "            moves_2[inv].append(ret)\n",
    "        else: continue\n",
    "\n",
    "df_trust_1_human = choices_to_df(moves_1, 'Human')\n",
    "df_trust_2_human = choices_to_df(moves_2[10], 'Human')\n",
    "df_trust_3_human = choices_to_df(moves_2[50], 'Human')\n",
    "df_trust_4_human = choices_to_df(moves_2[100], 'Human')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [50.0, 50.0, 40.0, 30.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0] \n",
    "df_trust_1_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "\n",
    "choices = [50.0, 50.0, 30.0, 30.0, 30.0, 60.0, 50.0, 40.0, 20.0, 20.0, 50.0, 40.0, 30.0, 20.0, 30.0, 20.0, 30.0, 60.0, 50.0, 30.0, 50.0, 20.0, 20.0, 30.0, 50.0, 30.0, 30.0, 50.0, 40.0] + [30]\n",
    "df_trust_1_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))\n",
    "\n",
    "choices = [20.0, 20.0, 20.0, 20.0, 15.0, 15.0, 15.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.0, 15.0, 20.0, 15.0, 15.0, 15.0, 15.0, 15.0, 20.0, 20.0, 15.0]\n",
    "df_trust_2_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "\n",
    "choices = [20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.0, 25.0, 30.0, 30.0, 20.0, 25.0, 30.0, 20.0, 20.0, 18.0] + [20, 20, 20, 25, 25, 25, 30]\n",
    "df_trust_2_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))\n",
    "\n",
    "choices = [100.0, 75.0, 75.0, 75.0, 75.0, 75.0, 100.0, 75.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 75.0, 100.0, 75.0, 75.0, 75.0, 100.0, 100.0, 100.0, 75.0, 100.0, 100.0, 100.0, 100.0, 75.0, 100.0, 75.0]\n",
    "df_trust_3_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "\n",
    "choices = [150.0, 100.0, 150.0, 150.0, 50.0, 150.0, 100.0, 150.0, 100.0, 100.0, 100.0, 150.0] + [100, 100, 100, 100, 100, 100, 100, 100]\n",
    "df_trust_3_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))\n",
    "\n",
    "choices = [200.0, 200.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 200.0, 200.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0]\n",
    "df_trust_4_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "\n",
    "choices = [225.0, 225.0, 300.0, 300.0, 220.0, 300.0, 250.0] + [200, 200, 250, 200, 200]\n",
    "df_trust_4_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0, 20.0, 20.0, 20.0, 15.0, 15.0, 15.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.0, 20.0, 20.0, 20.0, 20.0, 20.0, 15.0, 15.0, 20.0, 15.0, 15.0, 15.0, 15.0, 15.0, 20.0, 20.0, 15.0\n"
     ]
    }
   ],
   "source": [
    "records = json.load(open('records/trust_2_gpt4_2023_04_07-11_46_45_PM.json', 'r'))\n",
    "choices = extract_choices(records)\n",
    "print(', '.join([str(c) for c in choices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.0, 200.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 200.0, 200.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0\n"
     ]
    }
   ],
   "source": [
    "records = json.load(open('records/trust_4_gpt4_2023_04_08-12_24_56_AM.json', 'r'))\n",
    "choices = extract_choices(records)\n",
    "print(', '.join([str(c) for c in choices]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Goods\n",
    "\n",
    "#### Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/public_goods_linear_water.csv')\n",
    "df = df[df['Role'] == 'contributor']\n",
    "df = df[df['Round'] <= 3]\n",
    "df = df[df['Total'] == 20]\n",
    "df = df[df['groupSize'] == 4]\n",
    "df = df[df['move'] != None]\n",
    "df = df[(df['move'] >= 0) & (df['move'] <= 20)]\n",
    "df = df[df['gameType'] == 'public_goods_linear_water']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26686 25911 24122\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choices</th>\n",
       "      <th>hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26681</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26682</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26683</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26684</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26685</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26686 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       choices    hue\n",
       "0         20.0  Human\n",
       "1         13.0  Human\n",
       "2         10.0  Human\n",
       "3         10.0  Human\n",
       "4         10.0  Human\n",
       "...        ...    ...\n",
       "26681      0.0  Human\n",
       "26682     10.0  Human\n",
       "26683      2.0  Human\n",
       "26684      0.0  Human\n",
       "26685      0.0  Human\n",
       "\n",
       "[26686 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_1 = df[df['Round'] == 1]['move']\n",
    "round_2 = df[df['Round'] == 2]['move']\n",
    "round_3 = df[df['Round'] == 3]['move']\n",
    "print(len(round_1), len(round_2), len(round_3))\n",
    "df_PG_human = pd.DataFrame({\n",
    "    'choices': list(round_1)\n",
    "})\n",
    "df_PG_human['hue'] = 'Human'\n",
    "df_PG_human"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Payoffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choices</th>\n",
       "      <th>hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   choices        hue\n",
       "0     12.0  ChatGPT-3\n",
       "1     12.0  ChatGPT-3\n",
       "2     12.0  ChatGPT-3\n",
       "3     10.0  ChatGPT-3\n",
       "4     10.0  ChatGPT-3"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    # 'records/PG_basic_turbo_2023_05_09-02_49_09_AM.json',\n",
    "    # 'records/PG_basic_turbo_loss_2023_05_09-03_59_49_AM.json'\n",
    "    'records/PG_basic_gpt4_2023_05_09-11_15_42_PM.json',\n",
    "    'records/PG_basic_gpt4_loss_2023_05_09-10_44_38_PM.json',\n",
    "]\n",
    "\n",
    "choices = []\n",
    "for file_name in file_names:\n",
    "    with open(file_name, 'r') as f:\n",
    "        choices += json.load(f)['choices']\n",
    "choices_baseline = choices\n",
    "\n",
    "choices = [tuple(x)[0] for x in choices]\n",
    "df_PG_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))\n",
    "df_PG_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "df_PG_gpt4.head()\n",
    "df_PG_turbo.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bomb Risk Game\n",
    "\n",
    "1 safe, 0 bomb\n",
    "\n",
    "#### Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bomb_risk.csv')\n",
    "df = df[df['Role'] == 'player']\n",
    "df = df[df['gameType'] == 'bomb_risk']\n",
    "df.sort_values(by=['UserID', 'Round'])\n",
    "\n",
    "prefix_to_choices_human = defaultdict(list)\n",
    "prefix_to_IPW = defaultdict(list)\n",
    "prev_user = None\n",
    "prev_move = None\n",
    "prefix = ''\n",
    "bad_user = False\n",
    "for _, row in df.iterrows():\n",
    "    if bad_user: continue\n",
    "    if row['UserID'] != prev_user:\n",
    "        prev_user = row['UserID']\n",
    "        prefix = ''\n",
    "        bad_user = False\n",
    "\n",
    "    move = row['move']\n",
    "    if move < 0 or move > 100:\n",
    "        bad_users = True\n",
    "        continue\n",
    "    prefix_to_choices_human[prefix].append(move)\n",
    "\n",
    "    if len(prefix) == 0:\n",
    "        prefix_to_IPW[prefix].append(1)\n",
    "    elif prefix[-1] == '1':\n",
    "        prev_move = min(prev_move, 98)\n",
    "        prefix_to_IPW[prefix].append(1./(100 - prev_move))\n",
    "    elif prefix[-1] == '0':\n",
    "        prev_move = max(prev_move, 1)\n",
    "        prefix_to_IPW[prefix].append(1./(prev_move))\n",
    "    else: assert False\n",
    "    \n",
    "    prev_move = move\n",
    "\n",
    "    prefix += '1' if row['roundResult'] == 'SAFE' else '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 80 valid records\n",
      "# of wrong sum: 0\n",
      "# of correct sum: 80\n",
      "loaded 80 valid records\n",
      "# of wrong sum: 0\n",
      "# of correct sum: 80\n"
     ]
    }
   ],
   "source": [
    "prefix_to_choices_model = defaultdict(lambda : defaultdict(list))\n",
    "for model in ['ChatGPT-4', 'ChatGPT-3']:\n",
    "    if model == 'ChatGPT-4':\n",
    "        file_names = [\n",
    "            'bomb_gpt4_2023_05_15-12_13_51_AM.json'\n",
    "        ]\n",
    "    elif model == 'ChatGPT-3':\n",
    "        file_names = [\n",
    "            'bomb_turbo_2023_05_14-10_45_50_PM.json'\n",
    "        ]\n",
    "\n",
    "    choices = []\n",
    "    scenarios = []\n",
    "    for file_name in file_names:\n",
    "        with open(os.path.join('records', file_name), 'r') as f:\n",
    "            records = json.load(f)\n",
    "            choices += records['choices']\n",
    "            scenarios += records['scenarios']\n",
    "\n",
    "    assert len(scenarios) == len(choices)\n",
    "    print('loaded %i valid records' % len(scenarios))\n",
    "\n",
    "    prefix_to_choice = defaultdict(list)\n",
    "    prefix_to_result = defaultdict(list)\n",
    "    prefix_to_pattern = defaultdict(Counter)\n",
    "    wrong_sum = 0\n",
    "    for scenarios_tmp, choices_tmp in zip(scenarios, choices):\n",
    "\n",
    "        result = 0\n",
    "        for i, scenario in enumerate(scenarios_tmp):\n",
    "            prefix = tuple(scenarios_tmp[:i])\n",
    "            prefix = ''.join([str(x) for x in prefix])\n",
    "            choice = choices_tmp[i]\n",
    "            \n",
    "            prefix_to_choice[prefix].append(choice)\n",
    "            prefix_to_pattern[prefix][tuple(choices_tmp[:-1])] += 1\n",
    "\n",
    "            prefix = tuple(scenarios_tmp[:i+1])\n",
    "            if scenario == 1:\n",
    "                result += choice\n",
    "            prefix_to_result[prefix].append(result)\n",
    "\n",
    "    print('# of wrong sum:', wrong_sum)\n",
    "    print('# of correct sum:', len(scenarios) - wrong_sum)\n",
    "\n",
    "    prefix_to_choices_model[model] = prefix_to_choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prisoner Dilemma\n",
    "\n",
    "#### Human Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/push_pull.csv')\n",
    "df = df[df['gameType'] == 'push_pull']\n",
    "df = df[df['Role'] == 'player']\n",
    "df = df[(df['move'] == 0) | (df['move'] == 1)]\n",
    "# df = df[df['Round'] <= 2]\n",
    "df = df[df['groupSize'] == 2]\n",
    "\n",
    "counter = -1\n",
    "playIDs = []\n",
    "otherMoves = []\n",
    "for i, row in df.iterrows():\n",
    "    if row['Round'] == 1:\n",
    "        counter += 1\n",
    "    playIDs.append(counter)\n",
    "    roundResult = eval(row['roundResult'])\n",
    "    roundResult.remove(row['move'])\n",
    "    otherMoves.append(roundResult[0])\n",
    "df['playID'] = playIDs\n",
    "df['otherMove'] = otherMoves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45120236866004004 0.54879763133996\n"
     ]
    }
   ],
   "source": [
    "n_coo_human = 36269\n",
    "n_def_human = 44114\n",
    "r_coo_human = n_coo_human / (n_coo_human + n_def_human)\n",
    "r_def_human = n_def_human / (n_coo_human + n_def_human)\n",
    "print(r_coo_human, r_def_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(1, 1): 10584, (0, 1): 7686, (0, 0): 3821, (1, 0): 3635})\n"
     ]
    }
   ],
   "source": [
    "print(counter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666 0.08333333333333333\n",
      "0.7666666666666667 0.23333333333333334\n"
     ]
    }
   ],
   "source": [
    "n_coo_gpt4 = 29 + 0 + 0 + 26\n",
    "n_def_gpt4 = 0 + 1 + 1 + 3\n",
    "n_coo_turbo = 21 + 3 + 7 + 15\n",
    "n_def_turbo = 3 + 3 + 4 + 4\n",
    "r_coo_gpt4 = n_coo_gpt4 / (n_coo_gpt4 + n_def_gpt4)\n",
    "r_def_gpt4 = n_def_gpt4 / (n_coo_gpt4 + n_def_gpt4)\n",
    "r_coo_turbo = n_coo_turbo / (n_coo_turbo + n_def_turbo)\n",
    "r_def_turbo = n_def_turbo / (n_coo_turbo + n_def_turbo)\n",
    "print(r_coo_gpt4, r_def_gpt4)\n",
    "print(r_coo_turbo, r_def_turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choices</th>\n",
       "      <th>hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  choices        hue\n",
       "0    Push  ChatGPT-4\n",
       "1    Push  ChatGPT-4\n",
       "2    Push  ChatGPT-4\n",
       "3    Push  ChatGPT-4\n",
       "4    Push  ChatGPT-4"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    'records/PD_gpt4_two_rounds_push_2023_05_10-10_04_33_PM.json',\n",
    "    'records/PD_gpt4_two_rounds_pull_2023_05_08-08_57_08_PM.json'\n",
    "]\n",
    "\n",
    "choices = []\n",
    "for file_name in file_names:\n",
    "    with open(file_name, 'r') as f:\n",
    "        choices += json.load(f)['choices']\n",
    "choices_baseline = choices\n",
    "\n",
    "choices = [tuple(x)[0] for x in choices]\n",
    "df_PG_gpt4 = choices_to_df(choices, hue=str('ChatGPT-4'))\n",
    "df_PG_gpt4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choices</th>\n",
       "      <th>hue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Push</td>\n",
       "      <td>ChatGPT-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  choices        hue\n",
       "0    Push  ChatGPT-3\n",
       "1    Push  ChatGPT-3\n",
       "2    Push  ChatGPT-3\n",
       "3    Push  ChatGPT-3\n",
       "4    Push  ChatGPT-3"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\n",
    "    'records/PD_turbo_two_rounds_push_2023_05_08-06_03_40_PM.json',\n",
    "    'records/PD_turbo_two_rounds_pull_2023_05_08-09_23_13_PM.json',\n",
    "]\n",
    "\n",
    "choices = []\n",
    "for file_name in file_names:\n",
    "    with open(file_name, 'r') as f:\n",
    "        choices += json.load(f)['choices']\n",
    "choices_baseline = choices\n",
    "\n",
    "choices = [tuple(x)[0] for x in choices]\n",
    "df_PG_turbo = choices_to_df(choices, hue=str('ChatGPT-3'))\n",
    "df_PG_turbo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prisoner's Dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human\n",
      "ChatGPT-4\n",
      "ChatGPT-3\n"
     ]
    }
   ],
   "source": [
    "r_coo = r_coo_human\n",
    "r_def = r_def_human\n",
    "S = [r_coo * 400 + r_def * 000, r_coo * 700 + r_def * 300]\n",
    "P = [r_coo * 400 + r_def * 700, r_coo * 000 + r_def * 300]\n",
    "k = {}\n",
    "for model in ['Human', 'ChatGPT-4', 'ChatGPT-3']:    \n",
    "    if model == 'Human':\n",
    "        n_coo = n_coo_human\n",
    "        n_def = n_def_human\n",
    "    elif model == 'ChatGPT-4':\n",
    "        n_coo = n_coo_gpt4\n",
    "        n_def = n_def_gpt4\n",
    "    elif model == 'ChatGPT-3':\n",
    "        n_coo = n_coo_turbo\n",
    "        n_def = n_def_turbo\n",
    "    k[model] = [0] * n_coo + [1] * n_def\n",
    "    print(model)\n",
    "    # # estimate_beta(S, P, k[model])\n",
    "    # estimate_beta(S, P, k[model], r=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investment (Trust 2-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fig. 2: Turing Test\n",
    "\n",
    "Results may vary due to randomness in the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_Turing(samples_0, samples_1, n_bin=10, lim_a=0, lim_b=100, n_draw=100000):\n",
    "    hist_0 = np.histogram(samples_0, bins=n_bin, range=(lim_a, lim_b))[0] / len(samples_0)\n",
    "    n_wins = 0\n",
    "    n_ties = 0\n",
    "    for _ in tqdm(range(n_draw)):\n",
    "        try:\n",
    "            sample_0 = np.random.choice(samples_0)\n",
    "            sample_1 = np.random.choice(samples_1)\n",
    "            idx_0 = min(math.floor((sample_0 - lim_a) / (lim_b - lim_a) * n_bin), n_bin-1)\n",
    "            idx_1 = min(math.floor((sample_1 - lim_a) / (lim_b - lim_a) * n_bin), n_bin-1)\n",
    "            if hist_0[idx_1] > hist_0[idx_0]:\n",
    "                n_wins += 1\n",
    "            elif hist_0[idx_1] == hist_0[idx_0]:\n",
    "                n_ties += 1\n",
    "        except:\n",
    "            continue\n",
    "    return n_wins / n_draw, n_ties / n_draw, (n_draw - n_wins - n_ties) / n_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41561.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human (0.39281, 0.21017, 0.39702)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 42331.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.4529, 0.2067, 0.3404)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41831.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turbo (0.1448, 0.10203, 0.75317)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('human', simulate_Turing(df_dictator_human['choices'], df_dictator_human['choices']))\n",
    "print('gpt4', simulate_Turing(df_dictator_human['choices'], df_dictator_gpt4['choices']))\n",
    "print('turbo', simulate_Turing(df_dictator_human['choices'], df_dictator_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41071.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human (0.39721, 0.20656, 0.39623)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41262.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.65777, 0.34223, 0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41798.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turbo (0.34592, 0.19585, 0.45823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('human', simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_human['choices']))\n",
    "print('gpt4', simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_gpt4['choices']))\n",
    "print('turbo', simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 40985.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human (0.40989, 0.18031, 0.4098)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41846.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.38805, 0.18535, 0.4266)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 40884.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turbo (0.2389, 0.12527, 0.63583)\n"
     ]
    }
   ],
   "source": [
    "print('human', simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_human['choices']))\n",
    "print('gpt4', simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_gpt4['choices']))\n",
    "print('turbo', simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41925.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human (0.42409, 0.15061, 0.4253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 40608.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.24985, 0.10034, 0.64981)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 40726.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turbo (0.22239, 0.09342, 0.68419)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('human', simulate_Turing(df_trust_1_human['choices'], df_trust_1_human['choices']))\n",
    "print('gpt4', simulate_Turing(df_trust_1_human['choices'], df_trust_1_gpt4['choices']))\n",
    "print('turbo', simulate_Turing(df_trust_1_human['choices'], df_trust_1_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41102.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human (0.41664, 0.17169, 0.41167)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 40600.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.52819, 0.18393, 0.28788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41770.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turbo (0.52483, 0.18012, 0.29505)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('human', simulate_Turing(df_trust_3_human['choices'], df_trust_3_human['choices'], lim_b=150))\n",
    "print('gpt4', simulate_Turing(df_trust_3_human['choices'], df_trust_3_gpt4['choices'], lim_b=150))\n",
    "print('turbo', simulate_Turing(df_trust_3_human['choices'], df_trust_3_turbo['choices'], lim_b=150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert to numeric, coercing errors (invalid parsing will be set as NaN)\n",
    "# samples_0 = pd.to_numeric(df_PG_humapt4['choices'], errors='coerce')n['choices'], errors='coerce')\n",
    "# samples_1 = pd.to_numeric(df_PG_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_PG_turbo['choices'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_PG_turbo['choices'] = pd.to_numeric(df_PG_turbo['choices'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 12.]\n"
     ]
    }
   ],
   "source": [
    "print (np.unique(df_PG_turbo['choices']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41144.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human (0.43118, 0.14051, 0.42831)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41599.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.63632, 0.20653, 0.15715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41232.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.13817, 0.72381, 0.13802)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('human', simulate_Turing(df_PG_human['choices'], df_PG_human['choices'], lim_b=20))\n",
    "print('gpt4', simulate_Turing(df_PG_human['choices'], df_PG_gpt4['choices'], lim_b=20))\n",
    "print('gpt4', simulate_Turing(df_PG_turbo['choices'], df_PG_turbo['choices'], lim_b=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:40<00:00, 624.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human (0.43631, 0.12672, 0.43697)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:21<00:00, 1232.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4 (0.66277, 0.18436, 0.15287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:23<00:00, 1200.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turbo (0.61797, 0.17785, 0.20418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('human', simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_human['']))\n",
    "print('gpt4', simulate_Turing(prefix_to_choices_human[''],prefix_to_choices_model['ChatGPT-4']['']))\n",
    "print('turbo', simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_model['ChatGPT-3']['']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human 0.24761879117560937 0.5047624176487813 0.24761879117560937\n",
      "gpt4 0.03760019738833667 0.4593353072167 0.5030644953949632\n",
      "turbo 0.10528055268734268 0.473974596618688 0.42074485069396933\n"
     ]
    }
   ],
   "source": [
    "print('human', r_coo_human * r_def_human, r_coo_human * r_coo_human + r_def_human * r_def_human, r_def_human * r_coo_human)\n",
    "print('gpt4', r_coo_human * r_def_gpt4, r_coo_human * r_coo_gpt4 + r_def_human * r_def_gpt4, r_def_human * r_coo_gpt4)\n",
    "print('turbo', r_coo_human * r_def_turbo, r_coo_human * r_coo_turbo + r_def_human * r_def_turbo, r_def_human * r_coo_turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:02<00:00, 41589.78it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41491.21it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41208.75it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41092.37it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41027.39it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41716.32it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 40892.44it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 40642.91it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 40746.51it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 40910.17it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 40777.04it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41065.74it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 40915.84it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 40719.55it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41068.68it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41095.60it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 39808.19it/s]\n",
      "100%|██████████| 100000/100000 [00:02<00:00, 41238.63it/s]\n",
      "100%|██████████| 100000/100000 [02:41<00:00, 619.03it/s]\n",
      "100%|██████████| 100000/100000 [01:21<00:00, 1232.29it/s]\n",
      "100%|██████████| 100000/100000 [01:20<00:00, 1243.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# data = {\n",
    "\n",
    "#     'Average': {\n",
    "#         'Human': (0.39472, 0.20789, 0.39539),\n",
    "#         'GPT-4': (0.45068, 0.20923, 0.34009),\n",
    "#         'Turbo': (0.14191, 0.10243, 0.75566),\n",
    "#     },\n",
    "#     'Dictator': {\n",
    "#         'Human': (0.39672, 0.20789, 0.39539),\n",
    "#         'GPT-4': (0.45068, 0.20923, 0.34009),\n",
    "#         'Turbo': (0.14191, 0.10243, 0.75566),\n",
    "#     },\n",
    "#     'Ultimatum 1': {\n",
    "#         'Human': (0.39641, 0.20612, 0.39747),\n",
    "#         'GPT-4': (0.65658, 0.34342, 0.0),\n",
    "#         'Turbo': (0.35094, 0.19359, 0.45547),\n",
    "#     },\n",
    "#     'Ultimatum 2': {\n",
    "#         'Human': (0.4103, 0.17962, 0.41008),\n",
    "#         'GPT-4': (0.38777, 0.18544, 0.42679),\n",
    "#         'Turbo': (0.23764, 0.12665, 0.63571),\n",
    "#     },\n",
    "#     'Trust 1': {\n",
    "#         'Human': (0.42553, 0.1499, 0.42457),\n",
    "#         'GPT-4': (0.24883, 0.0994, 0.65177),\n",
    "#         'Turbo': (0.22511, 0.09314, 0.68175),\n",
    "#     },\n",
    "#     'Trust 3': {\n",
    "#         'Human': (0.41412, 0.17279, 0.41309),\n",
    "#         'GPT-4': (0.52801, 0.18393, 0.28806),\n",
    "#         'Turbo': (0.52552, 0.17863, 0.29585),\n",
    "#     },\n",
    "#     'Public Goods': {\n",
    "#         'Human': (0.42576, 0.14121, 0.43303),\n",
    "#         'GPT-4': (0.63608, 0.20542, 0.1585),\n",
    "#         'Turbo': (0.0, 1.0, 0.0),\n",
    "#     },\n",
    "#     'Bomb Risk': {\n",
    "#         'Human': (0.43803, 0.12385, 0.43812),\n",
    "#         'GPT-4': (0.66265, 0.18317, 0.15418),\n",
    "#         'Turbo': (0.61836, 0.18062, 0.20102),\n",
    "#     },\n",
    "#     'Prisoner‘s Dilemma': {\n",
    "#         'Human': (0.24761879117560937, 0.5047624176487813, 0.24761879117560937),\n",
    "#         'GPT-4': (0.03760019738833667, 0.4593353072167, 0.5030644953949632),\n",
    "#         'Turbo': (0.10528055268734268, 0.473974596618688, 0.42074485069396933),\n",
    "#     }\n",
    "# }\n",
    "\n",
    "Dictator_human_result = simulate_Turing(df_dictator_human['choices'], df_dictator_human['choices'])\n",
    "Dictator_gpt4_result = simulate_Turing(df_dictator_human['choices'], df_dictator_gpt4['choices'])\n",
    "Dictator_turbo_result = simulate_Turing(df_dictator_human['choices'], df_dictator_turbo['choices'])\n",
    "\n",
    "Ultimatum_1_human_result = simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_human['choices'])\n",
    "Ultimatum_1_gpt4_result = simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_gpt4['choices'])\n",
    "Ultimatum_1_turbo_result = simulate_Turing(df_ultimatum_1_human['choices'], df_ultimatum_1_turbo['choices'])\n",
    "\n",
    "Ultimatum_2_human_result = simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_human['choices'])\n",
    "Ultimatum_2_gpt4_result = simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_gpt4['choices'])\n",
    "Ultimatum_2_turbo_result = simulate_Turing(df_ultimatum_2_human['choices'], df_ultimatum_2_turbo['choices'])\n",
    "\n",
    "Trust_1_human_result = simulate_Turing(df_trust_1_human['choices'], df_trust_1_human['choices'])\n",
    "Trust_1_gpt4_result = simulate_Turing(df_trust_1_human['choices'], df_trust_1_gpt4['choices'])\n",
    "Trust_1_turbo_result = simulate_Turing(df_trust_1_human['choices'], df_trust_1_turbo['choices'])\n",
    "\n",
    "Trust_3_human_result = simulate_Turing(df_trust_3_human['choices'], df_trust_3_human['choices'], lim_b=150)\n",
    "Trust_3_gpt4_result = simulate_Turing(df_trust_3_human['choices'], df_trust_3_gpt4['choices'], lim_b=150)\n",
    "Trust_3_turbo_result = simulate_Turing(df_trust_3_human['choices'], df_trust_3_turbo['choices'], lim_b=150)\n",
    "\n",
    "Public_Goods_human_result = simulate_Turing(df_PG_human['choices'], df_PG_human['choices'], lim_b=20)\n",
    "Public_Goods_gpt4_result = simulate_Turing(df_PG_human['choices'], df_PG_gpt4['choices'], lim_b=20)\n",
    "Public_Goods_turbo_result = simulate_Turing(df_PG_turbo['choices'], df_PG_turbo['choices'], lim_b=20)\n",
    "\n",
    "Bomb_Risk_human_result = simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_human[''])\n",
    "Bomb_Risk_gpt4_result = simulate_Turing(prefix_to_choices_human[''],prefix_to_choices_model['ChatGPT-4'][''])\n",
    "Bomb_Risk_turbo_result = simulate_Turing(prefix_to_choices_human[''], prefix_to_choices_model['ChatGPT-3'][''])\n",
    "\n",
    "Prisoner_Dilemma_human_result = r_coo_human * r_def_human, r_coo_human * r_coo_human + r_def_human * r_def_human, r_def_human * r_coo_human\n",
    "Prisoner_Dilemma_gpt4_result = r_coo_human * r_def_gpt4, r_coo_human * r_coo_gpt4 + r_def_human * r_def_gpt4, r_def_human * r_coo_gpt4\n",
    "Prisoner_Dilemma_turbo_result = r_coo_human * r_def_turbo, r_coo_human * r_coo_turbo + r_def_human * r_def_turbo, r_def_human * r_coo_turbo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Average_human_result = tuple(sum(results) / 8 for results in zip(Dictator_human_result, Ultimatum_1_human_result, Ultimatum_2_human_result, Trust_1_human_result, Trust_3_human_result, Public_Goods_human_result, Bomb_Risk_human_result, Prisoner_Dilemma_human_result))\n",
    "Average_gpt4_result = tuple(sum(results) / 8 for results in zip(Dictator_gpt4_result, Ultimatum_1_gpt4_result, Ultimatum_2_gpt4_result, Trust_1_gpt4_result, Trust_3_gpt4_result, Public_Goods_gpt4_result, Bomb_Risk_gpt4_result, Prisoner_Dilemma_gpt4_result))\n",
    "Average_turbo_result = tuple(sum(results) / 8 for results in zip(Dictator_turbo_result, Ultimatum_1_turbo_result, Ultimatum_2_turbo_result, Trust_1_turbo_result, Trust_3_turbo_result, Public_Goods_turbo_result, Bomb_Risk_turbo_result, Prisoner_Dilemma_turbo_result))\n",
    "\n",
    "data = {\n",
    "    'Average': {\n",
    "        'Human': Average_human_result,\n",
    "        'GPT-4': Average_gpt4_result,\n",
    "        'GPT-3': Average_turbo_result,\n",
    "    },\n",
    "    'Dictator': {\n",
    "        'Human': Dictator_human_result,\n",
    "        'GPT-4': Dictator_gpt4_result,\n",
    "        'GPT-3': Dictator_turbo_result,\n",
    "    },\n",
    "    'Ultimatum 1': {\n",
    "        'Human': Ultimatum_1_human_result,\n",
    "        'GPT-4': Ultimatum_1_gpt4_result,\n",
    "        'GPT-3': Ultimatum_1_turbo_result,\n",
    "    },\n",
    "    'Ultimatum 2': {\n",
    "        'Human': Ultimatum_2_human_result,\n",
    "        'GPT-4': Ultimatum_2_gpt4_result,\n",
    "        'GPT-3': Ultimatum_2_turbo_result,\n",
    "    },\n",
    "    'Trust 1': {\n",
    "        'Human': Trust_1_human_result,\n",
    "        'GPT-4': Trust_1_gpt4_result,\n",
    "        'GPT-3': Trust_1_turbo_result,\n",
    "    },\n",
    "    'Trust 3': {\n",
    "        'Human': Trust_3_human_result,\n",
    "        'GPT-4': Trust_3_gpt4_result,\n",
    "        'GPT-3': Trust_3_turbo_result,\n",
    "    },\n",
    "    'Public Goods': {\n",
    "        'Human': Public_Goods_human_result,\n",
    "        'GPT-4': Public_Goods_gpt4_result,\n",
    "        'GPT-3': Public_Goods_turbo_result,\n",
    "    },\n",
    "    'Bomb Risk': {\n",
    "        'Human': Bomb_Risk_human_result,\n",
    "        'GPT-4': Bomb_Risk_gpt4_result,\n",
    "        'GPT-3': Bomb_Risk_turbo_result,\n",
    "    },\n",
    "    'Prisoner‘s Dilemma': {\n",
    "        'Human': Prisoner_Dilemma_human_result,\n",
    "        'GPT-4': Prisoner_Dilemma_gpt4_result,\n",
    "        'GPT-3': Prisoner_Dilemma_turbo_result,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Boyan/anaconda3/lib/python3.11/site-packages/altair/utils/deprecation.py:65: AltairDeprecationWarning: 'selection_multi' is deprecated.  Use 'selection_point'\n",
      "  warnings.warn(message, AltairDeprecationWarning, stacklevel=1)\n",
      "/Users/Boyan/anaconda3/lib/python3.11/site-packages/altair/vegalite/v5/api.py:398: AltairDeprecationWarning: The value of 'empty' should be True or False.\n",
      "  warnings.warn(\n",
      "/Users/Boyan/anaconda3/lib/python3.11/site-packages/altair/utils/deprecation.py:65: AltairDeprecationWarning: 'add_selection' is deprecated. Use 'add_params' instead.\n",
      "  warnings.warn(message, AltairDeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-fd07342c86f142eb91566c7ede9a5a0a.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-fd07342c86f142eb91566c7ede9a5a0a.vega-embed details,\n",
       "  #altair-viz-fd07342c86f142eb91566c7ede9a5a0a.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-fd07342c86f142eb91566c7ede9a5a0a\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-fd07342c86f142eb91566c7ede9a5a0a\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-fd07342c86f142eb91566c7ede9a5a0a\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"facet\": {\"spacing\": 10}}, \"data\": {\"name\": \"data-14d8df8d3b970ae36e03b0def9a2ecfe\"}, \"facet\": {\"field\": \"scenario\", \"header\": {\"labelOrient\": \"top\", \"titleOrient\": \"top\"}, \"title\": \"\", \"type\": \"nominal\"}, \"spec\": {\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"category\", \"scale\": {\"domain\": [\"Estimated More likely Human\", \"Estimated Equally likely Human/AI\", \"Estimated More Likely AI\"], \"range\": [\"#2ca02c\", \"#ff7f0e\", \"#d62728\"]}, \"type\": \"nominal\"}, \"opacity\": {\"condition\": {\"param\": \"param_12\", \"value\": 1, \"empty\": false}, \"value\": 0.6}, \"tooltip\": [{\"field\": \"scenario\", \"type\": \"nominal\"}, {\"field\": \"entity\", \"type\": \"nominal\"}, {\"field\": \"category\", \"type\": \"nominal\"}, {\"aggregate\": \"sum\", \"field\": \"percentage\", \"format\": \".2%\", \"type\": \"quantitative\"}], \"x\": {\"aggregate\": \"sum\", \"axis\": {\"format\": \".0%\"}, \"field\": \"percentage\", \"stack\": \"normalize\", \"title\": \"\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"entity\", \"sort\": {\"field\": \"entity\", \"op\": \"min\", \"order\": \"descending\"}, \"title\": \"\", \"type\": \"nominal\"}}, \"height\": 200, \"name\": \"view_8\", \"width\": 450}, \"columns\": 3, \"params\": [{\"name\": \"param_12\", \"select\": {\"type\": \"point\", \"fields\": [\"entity\"], \"on\": \"click\"}, \"views\": [\"view_8\"]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-14d8df8d3b970ae36e03b0def9a2ecfe\": [{\"scenario\": \"Average\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.3937198488969512}, {\"scenario\": \"Average\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.4520825246735421}, {\"scenario\": \"Average\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.29287256908591786}, {\"scenario\": \"Dictator\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.3967}, {\"scenario\": \"Dictator\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.45438}, {\"scenario\": \"Dictator\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.14193}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.39837}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.65785}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.34814}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.40965}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.38905}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.24063}, {\"scenario\": \"Trust 1\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.42213}, {\"scenario\": \"Trust 1\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.25052}, {\"scenario\": \"Trust 1\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.22425}, {\"scenario\": \"Trust 3\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.41392}, {\"scenario\": \"Trust 3\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.52874}, {\"scenario\": \"Trust 3\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.52555}, {\"scenario\": \"Public Goods\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.42719}, {\"scenario\": \"Public Goods\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.63781}, {\"scenario\": \"Public Goods\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.13793}, {\"scenario\": \"Bomb Risk\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.43418}, {\"scenario\": \"Bomb Risk\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.66071}, {\"scenario\": \"Bomb Risk\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.61927}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"Human\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.24761879117560937}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"GPT-4\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.03760019738833667}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"GPT-3\", \"category\": \"Estimated More likely Human\", \"percentage\": 0.10528055268734268}, {\"scenario\": \"Average\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.21109280220609766}, {\"scenario\": \"Average\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.2335394134020875}, {\"scenario\": \"Average\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.25907307457733597}, {\"scenario\": \"Dictator\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.20854}, {\"scenario\": \"Dictator\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.20706}, {\"scenario\": \"Dictator\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.10446}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.20343}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.34215}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.19567}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.17863}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.18479}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.12676}, {\"scenario\": \"Trust 1\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.15025}, {\"scenario\": \"Trust 1\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.10127}, {\"scenario\": \"Trust 1\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.0929}, {\"scenario\": \"Trust 3\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.17226}, {\"scenario\": \"Trust 3\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.18442}, {\"scenario\": \"Trust 3\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.17834}, {\"scenario\": \"Public Goods\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.14234}, {\"scenario\": \"Public Goods\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.20441}, {\"scenario\": \"Public Goods\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.72082}, {\"scenario\": \"Bomb Risk\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.12853}, {\"scenario\": \"Bomb Risk\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.18488}, {\"scenario\": \"Bomb Risk\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.17966}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"Human\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.5047624176487813}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"GPT-4\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.4593353072167}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"GPT-3\", \"category\": \"Estimated Equally likely Human/AI\", \"percentage\": 0.473974596618688}, {\"scenario\": \"Average\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.3951873488969512}, {\"scenario\": \"Average\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.31437806192437046}, {\"scenario\": \"Average\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.44805435633674623}, {\"scenario\": \"Dictator\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.39476}, {\"scenario\": \"Dictator\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.33856}, {\"scenario\": \"Dictator\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.75361}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.3982}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.0}, {\"scenario\": \"Ultimatum 1\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.45619}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.41172}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.42616}, {\"scenario\": \"Ultimatum 2\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.63261}, {\"scenario\": \"Trust 1\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.42762}, {\"scenario\": \"Trust 1\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.64821}, {\"scenario\": \"Trust 1\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.68285}, {\"scenario\": \"Trust 3\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.41382}, {\"scenario\": \"Trust 3\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.28684}, {\"scenario\": \"Trust 3\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.29611}, {\"scenario\": \"Public Goods\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.43047}, {\"scenario\": \"Public Goods\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.15778}, {\"scenario\": \"Public Goods\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.14125}, {\"scenario\": \"Bomb Risk\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.43729}, {\"scenario\": \"Bomb Risk\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.15441}, {\"scenario\": \"Bomb Risk\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.20107}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"Human\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.24761879117560937}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"GPT-4\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.5030644953949632}, {\"scenario\": \"Prisoner\\u2018s Dilemma\", \"entity\": \"GPT-3\", \"category\": \"Estimated More Likely AI\", \"percentage\": 0.42074485069396933}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the data into a format suitable for Altair\n",
    "records = []\n",
    "for scenario, scenario_data in data.items():\n",
    "    for entity, values in scenario_data.items():\n",
    "        records.append({\n",
    "            \"scenario\": scenario,\n",
    "            \"entity\": entity,\n",
    "            \"Estimated More likely Human\": values[0],\n",
    "            \"Estimated Equally likely Human/AI\": values[1],\n",
    "            \"Estimated More Likely AI\": values[2]\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame.from_records(records)\n",
    "\n",
    "# Melt the DataFrame to have category names and percentages in separate columns\n",
    "df_melted = df.melt(id_vars=['scenario', 'entity'], \n",
    "                    value_vars=['Estimated More likely Human', 'Estimated Equally likely Human/AI', 'Estimated More Likely AI'],\n",
    "                    var_name='category', value_name='percentage')\n",
    "\n",
    "# Define the color scale\n",
    "color_scale = alt.Scale(domain=['Estimated More likely Human', 'Estimated Equally likely Human/AI', 'Estimated More Likely AI'],\n",
    "                        range=['#2ca02c', '#ff7f0e', '#d62728'])\n",
    "\n",
    "# Create the selection for the interactive highlight\n",
    "highlight = alt.selection_multi(on='click',fields=['entity'], empty='none')\n",
    "# alt.selection_single(on='mouseover', fields=['category'], empty='none')\n",
    "\n",
    "# Define the base chart with a bar mark and the selection highlight\n",
    "base_chart = alt.Chart(df_melted).mark_bar().encode(\n",
    "    x=alt.X('sum(percentage)', stack=\"normalize\", title='', axis=alt.Axis(format='.0%')),\n",
    "    y=alt.Y('entity:N', title='', sort=alt.EncodingSortField('entity', op='min', order='descending')),\n",
    "    color=alt.Color('category', scale=color_scale),\n",
    "    opacity=alt.condition(highlight, alt.value(1), alt.value(0.6)),\n",
    "    tooltip=[alt.Tooltip('scenario'), alt.Tooltip('entity'), alt.Tooltip('category'), alt.Tooltip('sum(percentage):Q', format='.2%')]\n",
    ").properties(\n",
    "    width=450,  # Width of the individual charts\n",
    "    height=200\n",
    ").add_selection(\n",
    "    highlight,\n",
    ")\n",
    "\n",
    "# Facet the base chart into two rows\n",
    "faceted_chart = base_chart.facet(\n",
    "    facet=alt.Facet('scenario', title='', header=alt.Header(labelOrient='top', titleOrient='top')),\n",
    "    columns=3  # Display four graphs in each column\n",
    ")\n",
    "\n",
    "# Adjust spacing between the rows for better readability\n",
    "faceted_chart = faceted_chart.configure_facet(spacing=10)\n",
    "\n",
    "# Show the chart\n",
    "faceted_chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
